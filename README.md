краен срок: 12.06.2022
---
# Паяци от Марс

В четвъртото домашно ще си имплементираме паяче, което броди по всеобхватния Web, започвайки от зададена му страница и продължавайки по нейните линкове.

Ще се възползваме от това, че нашият паяк има много крака, за да имплементираме това бродене конкурентно и паралелно, използвайки `Future`. След като страницата бъде извлечена, ще я предадем на процесор, който да я обработи по определен начин (отново конкурентно) и който ще ни генерира резултат за тази страница. Накрая моноидно ще съберем всички резултати от всички страници.

## С какво разполагаме

HTTP е синхронен request -> response протокол, което пасва перфектно на модела на Future-ите. Всеки response на заявка към определен URL (или по-точно, към определен ресурс), се състои от:

* status код, изразяващ резултата от обработката на заявката,
* списък от header-и под формата на ключ -> стойност, описващи response-а,
* тяло, съдържащо резултатния ресурс, например заявената web страница.

Това ще описваме чрез следния тип:

```scala
trait HttpResponse:
  def status: Int
  def headers: Map[String, String]
  def bodyAsBytes: Array[Byte]

  def body: String = ...

  def contentType: Option[ContentType] = ...

  def isSuccess: Boolean = 200 <= status && status < 300
  def isClientError: Boolean = 400 <= status && status < 500
  def isServerError: Boolean = 500 <= status && status < 600
```

Status кода е число между 100 и 599, като всеки си има различен смисъл и попада в една от четири категории. Дефинирали сме проверка за три от тях – дали е статус за успех, статус за клиентска грешка или статус за сървърна грешка. Най-често успех се обозначава чрез 200.

Тялото представяме чрез масив от байтове, но за улеснение, в случаите когато очакваме то да е текст, сме имплементирали метод `body`, който превръща байтовете към низ

Един специален header, за който сме създали специален тип, е `Content-Type`:

```scala
case class ContentType(mimeType: String, charset: Option[Charset])
```

Ако е зададен, той съдържа типа на съобщението, съдържащо се в body-то (HTML, PNG картинка, текст и т.н.) и символна кодировка, ако то е текстово. В придружаващия обект на `ContentType` сме описали MIME типа на HTML (`text/html`) и текстовите документи (`text/plain`).

Един HTTP клиент, който поддържа единствено извличане на HTTP ресурси, изглежда по следния начин:

```scala
trait HttpClient:
  def get(url: String): Future[HttpResponse]
```

Предоставили сме ви имплементация на такъв клиент чрез библиотеката [async-http-client](https://github.com/AsyncHttpClient/async-http-client) в класа `AsyncHttpClient`. Характерното за него е, че той имплементира така наречения reactor pattern, който ни позволява да използваме неблокиращ вход/изход, с което една нишка може да се грижи за множествено мрежови комуникации без да бъде блокирана от всяко входно/изходно действие (както се случва при стандартния вход/изход).

`get` методът извършва заявка към съответния ресурс и връща `Future` с получения response.

В `math` пакета може да откриете имплементацията на моноид, която постигнахме по време на лекциите.

## Имплементация на web паяк (6 точки)

В `Spidey.scala` ще намерите следното:

```scala
case class SpideyConfig(
  maxDepth: Int,
  sameDomainOnly: Boolean = true,
  tolerateErrors: Boolean = true,
  retriesOnError: Int = 0
)

class Spidey(httpClient: HttpClient)(implicit ex: ExecutionContext):
  def crawl[O : Monoid](url: String, config: SpideyConfig)
                       (processor: Processor[O]): Future[O] = ???
```

Вашата първа и основна задача е да имплементирате метода `crawl`. Той има множествено входни параметри/конфигурации, затова помислете добре как ще разбиете имплементацията му на малки части (на композиция от лесно разбираеми функции).

`SpideyConfig` осигурява конфигурационни параметри за начина на работа на `crawl`, но за основната имплементацията ще се съсредоточим само върху `maxDepth`, останалите ще разгледаме като допълнение по-късно.

Целта на `crawl` е да обходи всички линкнати ресурси, започвайки от `url` и стигайки до дълбочина `maxDepth` линка от него, да изпрати `HttpResponse`-а, получен от всеки от тях, към подадения процесор, и да комбинира (слее) резултати от тип `O`, генерирани от всяко извикване на процесора.

Процесорите имат следния интерфейс:

```scala
trait Processor[O]:
  def apply(url: String, response: HttpResponse): Future[O]
``` 

Пълните изисквания към `crawl` са следните:

* Първият ресурс, който извлича, е `url`. Той е на дълбочина 0 от себе си, всички негови линкове са на дълбочинно ниво 1, всички тяхни на 2 и т.н.
* Ще обработваме само HTTP линковете. За да проверите дали даден линк е валиден HTTP линк използвайте `HttpUtils.isUrlHttp`.
* Всеки един ресурс трябва да бъде извлечен най-много веднъж, тоест ако вече е бил срещнат на по-ранно ниво да не се повтаря неговото извличане. За да постигнем това лесно чрез `Future`, ще искаме да имаме конкурентност в извличането и обработването на ресурсите само в едно и също дълбочинно ниво. Тоест първо извличваме и обработваме `url`, след това всички адреси/ресурси на ниво 1, след като те са готови, всички на ниво 2 (без тези, които вече са били обработени на ниво 0 или 1), и т.н.
  
  __Забележка__: Това жертва конкурентността в определени моменти (например една много бавна заяка би отложила минаването към обработка на следващото ниво) и също носи риск от пренатоварване на сайтовете, които достъпваме (с увеличаващата се дълбочина навярно ще се увеличава и броят страници, които трябва да се обработват паралелно, поради което и някои сайтове биха ни ограничили достъпа временно). Решаването на този проблем изисква допълни средства за управление на състояние, които ще разгледаме по-късно в курса като разширена функционалност към `IO` ефекта. За целите на това задание използването на `Future` е напълно достатъчно.
* Ще обработваме всички типове ресурси, но ще извличаме линкове само от HTML ресурсите. За да извлечете всички линкове от HTML страница използвайте `HtmlUtils.linksOf`. За всички останали типове считаме, че не съдържат линкове.
* Обработката на `HttpResponse` от процесор започва веднага щом response-ът бъде получен.
* Всяко извикване на `apply` на процесор генерира резултат от тип `O`, който е моноиден. Резултатът от `crawl` трябва да е моноидното събиране на всички обекти от тип `O`, като редът, в който ще бъдат събрани, трябва да съвпада с реда, върнат от `HtmlUtils.linksOf`. Използвайте метода на `List` [`distinct`](https://scala-lang.org/api/3.x/scala/collection/immutable/List.html#distinct-0) за премахване на повторенията.
  
  Като пример, един възможен процесор може да брои честотата на всяка дума в страницата. Тогава типът `O` ще бъде `WordCount`, който на всяка дума съпоставя бройка. Крайнитът резултът от `crawl` ще бъде честотата на всяка от срещнатите думи във всички посетени страници.

**Съвет**: Помислете за помощен тип, в който да съхранявате резултатите от обработката на даден URL, докато чакате обработката на останалите.

## Допълнения към `crawl` (3 точки)

`crawl` може допълнително да бъде настройвано със следните параметри:

* `sameDomainOnly` – ако е `true`, то се следват само линкове към същия домейн като `url`. Използвайте `HttpUtils.sameDomain` за да проверите дали два URL-а имат един и същи домейн.
* `tolerateErrors` – при стойност `false` първият fail-нал `Future` в цялата композиция на `crawl` трябва да доведе до fail резултат от `crawl` със същата грешка (това съответства и на поведението, което получаваме при композиция на `Future`-и по подразбиране, тоест така най-вероятно се държи имплементацията ни от предната част на домашното, без да правим нищо допълнително). При стойност `true`, при fail, независимо дали от `HttpClient.get` или `processor.apply`, считаме, че за този ресурс като краен резултат сме получили моноидна нула (`identity` на моноид) и че той няма никакви линкове и **не** прекъсваме изчислението на останалите ресурси.

  **Забележка**: тук за fail се счита само и единствено достигане на `Failure` състояние на `Future`-а
* `retriesOnError` – ако е по-голямо от 0, то при fail на `Future`-а от `HttpClient.get` или при негов успех, но със status код, който е server error (между 500 и 599), автоматично опитваме отново да извършим request-а чрез повторно извикване на `HttpClient.get`. Това повтаряме до успех или до най-много `retriesOnError` пъти. При краен неуспех връщаме резултатът на `HttpClient.get` от последния `retry`.

**Насоки**: възползвайте се от [допълнителните операциите върху `Future`, с които се запознахме по време на лекциите](https://scala-fmi.github.io/scala-fmi-2022/lectures/08-concurrency.html#/%D0%BF%D0%BE%D0%BB%D0%B5%D0%B7%D0%BD%D0%B8-%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%B8). Освен тях полезна би могла да ви бъде и операцията [`transformWith`](https://scala-lang.org/api/3.x/scala/concurrent/Future.html#transformWith-a8c).

## Процесори (2 точки)

Последната стъпка, преди да можем да пуснем нашия паяк, е имплементирането на самите процесори, които обработват уеб страниците/ресурсите. Всеки процесор генерира определен тип. За всеки от тях трябва да реализирате и моноидната имлементация на този тип. Ще искаме от вас да създадете три процесора:

### `WordCounter`

`WordCounter` генерира резултат от тип `WordCount`, съпоставящ всяка дума на брой срещания. 

За успешните response-и (status код между 200 и 299), които са HTML страници (`text/html`) или страници с чист текст (`text/plain`), ще искаме да преброим колко пъти се среща всяка дума в тях. За да извлечете текста от HTML документ използайте `HtmlUtils.toText`. За да вземете списък от всички думи в даден текст използвайте `WordCount.wordsOf`.

За неуспешните response-и връщайте `WordCount` с празен map.

### `FileOutput`

`FileOutput` записва ресурса във файл с уникално-генерирано име, ако response-ът е бил успешен. Резултатният тип е `SavedFiles`, който съпоставя за всеки URL къде по файловата система е бил записан. Очевидно, едно извикване на `apply` ще генерира `SavedFiles` с най-много един елемент в своя map.

`FileOutput` приема `targetDir` за това къде да бъдат записвани файловете. Името на файл за определен URL може да генерирате чрез `generatePathFor`.

За да извършите самото записване използвайте Java функцията [`Files.write`](https://docs.oracle.com/en/java/javase/18/docs/api/java.base/java/nio/file/Files.html#write(java.nio.file.Path,byte%5B%5D,java.nio.file.OpenOption...)). Извикването на тази функция блокира текущата нишка докато резултатът не бъде записан успешно на файловата система. Практика е операциите, които блокират нишки, или които се изпълняват продължително време, да бъдат стартирани върху създаден за тях отделен pool от нишки, за да не пречат на другите асинхронни операции. Затова `FileOutput` приема и `ExecutionContext`, в който да бъде извършено записването.

### `BrokenLinkDetector`

`BrokenLinkDetector` генерира списък от всички URL-и, за които сме получили отговор със статус код 404 (Not Found). Така можем да намерим всички счупени линкове на даден сайт.

## Command-line паяк

За да видим нашето паяче в действие, в `SpideyApp` сме имплементирали приложение, което приема настройки от потребителя и изпълнява някой от реализираните процесори върху зададен URL и неговите линкове. Изпълзсването му е описано в текста на `printUsage`.

Забележете, че създаваме два `ExecutionContext`-а – един default-тен и един за блокиращи операции, който може да бъде използван за `FileOutput`.

Аргументите към приложението се подават на `args` масива на `main`. За да изпълните приложението и да ги подадете имате няколко варианта:

* Ако изполвате IntelliJ IDEA от `Run -> Edit Configurations` може да зададете `Program arguments` за `SpideyApp`
* може да стартирате приложението през `sbt` с `sbt "run <аргументи>"` (или директно `run <аргументи>`, ако сте вече в `sbt`)
* Може да използвате `sbt` plugin-а `assembly`, който създава изпълним `.jar` файл чрез `sbt assembly`. В `project/plugins.sbt` може да видите как сме го добавили към текущия проект. Генерираният `.jar` се появява в `target/scala-3.1.1` и може да се изпълни чрез:
  
  `java -jar target/scala-3.1.1/spiders-from-mars-assembly-0.1.jar <аргументи>`

## Type class за конкурентност (5,5 точки)

Както видяхме на лекциите, `Future` от стандартната библиотека на Scala има своите недостатъци, свързани с това, че започва изчисленията eagerly, memoize-ва резултатите, и в крайна сметка води до нарушаване на референтната прозрачност в някои случаи. Поради това много често в по-чисто функционален Scala код използваме конкурентни ефекти, подобни на асинхронен IO, който имплементирахме на лекциите. Това значи обаче, че всеки автор на библиотеки на Scala е изправен пред избор кой ефект за конкурентност да използват в своята библиотека (`Future`, защото е стандартен, `IO` от някоя библиотека, свой си?), а авторите на приложения пред нуждата да свързват и адаптират отделни парчета код, решили да използват различни ефекти.

За щастие, за разлика от например Java, където това също е често срещан проблем, в Scala имаме подходящи механизми, които биха ни позволили да делегираме това решение към авторите на крайните приложения. Ще опитаме да постигнем това чрез type class за конкурентност.

Type class-ът, който ще дефинираме, изглежда по следния начин:

```scala
trait Concurrent[F[_]]:
  def pure[A](a: A): F[A]
  def failed[A](e: Throwable): F[A]

  def eval[A](a: => A): F[A]
  def evalOn[A](a: => A, ec: ExecutionContext): F[A]

  def parallelZip[A, B](fa: F[A], fb: F[B]): F[(A, B)]

  extension [A](fa: F[A])
    def flatMap[B](f: A => F[B]): F[B]
    def flatMapError(f: Throwable => F[A]): F[A]

  def async[A](registerCallback: (ExecutionContext, Callback[A]) => Unit): F[A]
```

Тук `F` е конкурентният ефект, а в кода горе за момента виждате само основните операции, които биха били различни за всеки един ефект:

* `pure[A](a: A): F[A]` – обвива изчислената стойност в ефекта `F`. (Забележка: това е алтернативно име за монадната операция `unit`)
* `failed[A](e: Throwable): F[A]` – обвива грешката в ефекта `F`
* `eval[A](a: => A): F[A]` – изчислява `a` конкурентно в ефекта `F` (върху текущия за ефекта `ExecutionContext`)
* `evalOn[A](a: => A, ec: ExecutionContext): F[A]` – изчислява `a` конкурентно върху `ExecutionContext`-а `ec`

  __Забележка__: тази сигнатура на `evalOn` се налага поради това че `Future` стартира eagerly. Ако не трябваше да покриваме `Future` сигнатурата по-скоро би била:

  `evalOn[A](a: F[A], ec: ExecutionContext): F[A]`
* `parallelZip[A, B](fa: F[A], fb: F[B]): F[(A, B)]` – комбинира ефектите `fa` и `fb`, като изчислява двата ефекта конкурентно един спрямо друг. Причината да изберем `parallelZip` като име е за да наблегнем, че искаме от него да комбинира ефектите конкурентно и независимо, което не ни е гарантирано от стандартния `zip` (който по конвенция при наличие на Монада трябва да е съвместим със поведението на `flatMap`, тоест да бъде имплементиран чрез него)
* `extension [A](fa: F[A]) def flatMap[B](f: A => F[B]): F[B]` – познатата ни операция – `flatMap`-ва успешен резултат към ефект, който да продължи изчислението
* `extension [A](fa: F[A]) def flatMapError(f: Throwable => F[A]): F[A]` – подобно на `flatMap`, но `flatMap`-ва ефекта само ако в него бъде получен резултат за грешка. Ако е резултат за успех то той не се променя
* `async[A](registerCallback: (ExecutionContext, Callback[A]) => Unit): F[A]` – позволява връзка към външния свят, тоест към асинхронни операции, имплементирани чрез callback. `async` позволява на използващите type class-а да адаптират такава асинхронна операция към ефекта `F`, като за целта предоставят функция `registerCallback`, която да позволи на `F` да регистрира свой callback. Освен callback `Concurrent` имплементацията предоставя и текущия `ExecutionContext`, в който би могъл да се изпълни callback-а, когато асинхронната операция завърши.

За вас допълнително сме имплементирали `map` и `parallelZipMap` операциите като производни на горните.

От абстрактна гледна точка `Concurrent` чрез операциите `pure` и `flatMap` образува монада (тоест може да наследи `Monad`), която поддържа и състояния за грешки (`flatMapError` е типично за такива монади, които още се наричат `MonadError`). Освен това алтернативно образува и независим апликатив чрез `pure`, `map` и `parallelZip`. Така операциите, които са чисто свързани с конкурентност и асинхронност, са `eval`, `evalOn`, `async` и `parallelZip`. За домашното решихме да не въвеждаме тези абстракции поради объркването, което настава от наличието и на монадна и на апликативна форма, които не са съвместими (монадите не могат да образуват апликатив с истински независими операции, тъй като тяхната имплементация на `zip` е производна на `flatMap`). На лекциите ще разгледаме как можем да изчистим това по добър начин и как библиотеката Cats го постига.

### Инстанции на `Concurrent` за `Future` и `IO`

Като първа стъпка ще искаме от вас да имплементирате type class-а за `Future` и за ефекта `IO`, който имплементирахме на лекциите. `IO` може да откриете в `homework4.concurrent` пакета на предоставения код.

Добавете инстанцията за всеки от ефектите към придружаващия обект на `Concurrent`.

### Допълнителни операции

Ще желаем от вас да имплементирате и следните допълнителни операции върху `Concurrent`:

* `parallelSequence[A](fas: List[F[A]]): F[List[A]]` – имплементация на `sequence`, използваща `parallelZip`
* `extension [A](fa: F[A]) def recover(pf: PartialFunction[Throwable, A]): F[A]` – map-ва грешката, само ако може да бъде обработена от частичната функция `pf`. В противен случай запазва оригиналната стойност
* `extension [A](fa: F[A]) def recoverWith(pf: PartialFunction[Throwable, F[A]]): F[A]` – flatMap-ва грешката, само ако може да бъде обработена от частичната функция `pf`. В противен случай запазва оригиналната стойност
* `extension [A](fa: F[A]) transformWith[B](f: Try[A] => F[B]): F[B]` – функция, която ни позволява да flatMap-нем и успешните стойности и грешките наведнъж
* `fromFuture[A](fa: => Future[A]): F[A]` – адаптиране на вече реализиран `Future` към ефекта `F`. Удобен, поради това че навярно много от написания `Scala` код, който ще срещнем, би използвал `Future. Това ни позволява да го адаптираме към ефекта, който ние използваме

Не се притеснявайте да имплементирате и допълнителни операции освен описаните, ако имате нужда от такива.

### Паяк чрез `Concurrent`

Основната ни цел е да предоставим нова имплементация на `Spidey`, използваща произволен `Concurrent` ефект:

```scala
class GenericSpidey[F[_] : Concurrent](httpClient: GenericHttpClient):
  def crawl[O : Monoid](startingUrl: String, config: SpideyConfig)
                       (processor: GenericProcessor[O]): F[O] = ???
```

За целта имаме и нова версия на интерфейсите за HTTP клиент и процесор, също използвайки конкурентния ефект.

Имплементирайте `crawl` отново чрез `F`.

__Забележка__: Тук очакваме от вас пълна имплементация на `crawl` без да използвате например `Concurrent[F].fromFuture` за да адаптирате кода към `crawl` от `Spidey`. Навярно ще се получи почти пълно повторение на кода между двата паяка. Ако това ви притеснява може да имплементирате `Spidey.crawl` чрез `GenericSpidey.crawl`, но не е никакъв проблем и ако не го направите.

### `Concurrent` процесори

В кода сме предоставили имплементация на `GenericBrokenLinkDetector`, `GenericFileOutput` и `GenericWordCounter`, които чрез `Concurrent[F].fromFuture` адаптират съответните им `Future` имплементации (имплементирани от вас по-горе).

Ще искаме от вас да реализирате и още един процесор:

```scala
class CombinedProcessor[A, B](processorA: GenericProcessor[A], processorB: GenericProcessor[B])
  extends GenericProcessor[(A, B)]:

  def apply[F[_] : Concurrent](url: String, response: HttpResponse): F[(A, B)] = ???
```

`CombinedProcessor` комбинира два други процесора, като конкурентно изпълнява и двата върху response-а. Резултатът от `CombinedProcessor` е двойка от резултата от всеки от процесорите.

### Command-line generic паяк

Като последна стъпка, преправете SpideyApp да използва `GenericSpidey`.

(Като допълнително незадължително упражнение може да опитате да добавите и поддръжка на `CombinedProcessor`.)

## Стил (4,5 точки*)

В това домашно отново част от точките ще са за стил на цялостното решение.

За изключително добри решения ще получите и допълнително над тези 4,5 точки, Аналогично, при лош стил и ненужно използване на странични ефекти, `var` или `return`, си запазваме правото и да отнемем точки.

## Тестове (бонус точки)

Тестването на concurrent програми обикновено е малко по-трудно.

За да тествате `Future`-и имате няколко възможни подхода

1. Да изполвате `Await.result` във вашите тестове, който блокира нишката на теста докато не се върне резултат, след което да проверите дали резултатът е очакваният.
2. Да използвате [`ScalaFutures`](https://www.scalatest.org/scaladoc/3.2.11/org/scalatest/concurrent/ScalaFutures.html) разширенията към ScalaTest.
3. Да използвате [async разширенията](http://www.scalatest.org/user_guide/async_testing) към ScalaTest

Препоръчваме ви 2 или 3.

При тестване на имплементацията на `Concurrent` версиите на кода обикновено подходите са или да се избере един конкретен ефект, с който да са тестовете, или да се създаде специален ефект за тестовете, който би ги улеснил. В случая препоръчваме първото, или с `Future` или с `IO` и иползване на неговото `unsafeRunSync`.

При тестването на паяка може да предоставите stub за HTTP клиента и процесора, или да използвате [ScalaMock](http://scalamock.org/) за тяхното мокване.

Качествено тестване с такива подходи са теми, които излизат извън рамките на курса, и не очакваме от вас да го направите. Но за любопитните, при добри тестове за `Spidey` или `GenericSpidey` ще ви дадем бонус точки :).

## Форматиране

За да ви насочим към консистентен стил към домашно отново сме добавили инструмента [`scalafmt`](https://scalameta.org/scalafmt/). За да форматирате кода си може да използвате `scalafmt` командата на `sbt` (идваща от `sbt-scalafmt` plugin-а, който сме добавили) или да изпълните `scalafmt` от командния ред. Вижте [документацията на scalafmt](https://scalameta.org/scalafmt/docs/installation.html) за как да интегрирате и вашите IDE или редактор.

В `.scalafmt.conf` сме добавили наша конфигурация за формат. Чувствайте се напълно свободни да я промените, ако предпочитате различен стил. Важното е накрая кодът да е консистентен.

## Оценяване

Общият брой точки от това домашно е 21.
